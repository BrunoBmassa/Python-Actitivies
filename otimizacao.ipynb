{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjQXIhm5cUjJU/eTwJocg8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoBmassa/Python-Actitivies/blob/main/otimizacao.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1ThdUwvvyD-"
      },
      "outputs": [],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyspark\n",
        "import gdown\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "GOlhK47Wv2wf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark= SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "-92_DVGqwjx7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leia o arquivo 'videos-preparados.snappy.parquet' no dataframe 'df_video'\n",
        "\n",
        "df_video_url='https://drive.google.com/file/d/1A1iKcyCfaa0ObhTVN-3EfhiALnB0aCN0/view?usp=drive_link'\n",
        "# Extração do arquivo pela URL\n",
        "file_id = df_video_url.split('/')[-2]\n",
        "# Download do arquivo\n",
        "output_file = 'videos-preparados.snappy.parquet'\n",
        "gdown.download(id=file_id, output=output_file, quiet=False)\n",
        "#Leitura do arquivo inferindo o esquema\n",
        "df_video = spark.read.parquet(output_file)\n"
      ],
      "metadata": {
        "id": "_QJ5sMKUwklk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Leia o arquivo 'videos-preparados.snappy.parquet' no dataframe 'df_video'\n",
        "\n",
        "df_comments_url='https://drive.google.com/file/d/1nfM60gLkNeR_sMPQC8O3fvySdovEbrlt/view?usp=drive_link'\n",
        "# Extração do arquivo pela URL\n",
        "file_id2 = df_comments_url.split('/')[-2]\n",
        "# Download do arquivo\n",
        "output_file2 = 'video-comments-tratados.snappy.parquet'\n",
        "gdown.download(id=file_id2, output=output_file2, quiet=False)\n",
        "#Leitura do arquivo inferindo o esquema\n",
        "df_comments = spark.read.parquet(output_file2)"
      ],
      "metadata": {
        "id": "LJ7BwjoOw2Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomear colunas para evitar espaços e inconsistências\n",
        "df_video_cleaned = df_video.withColumnRenamed(\"Video ID\", \"video_id\")\n",
        "df_comments_cleaned = df_comments.withColumnRenamed(\"Video ID\", \"video_id\")"
      ],
      "metadata": {
        "id": "hyB0sb6NvzyD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Crie tabelas temporárias para ambos os dataframe\n",
        "\n",
        "df_video_cleaned.createOrReplaceTempView('video_table')\n",
        "df_comments_cleaned.createOrReplaceTempView('comments_table')"
      ],
      "metadata": {
        "id": "dJ7ldQHhxQIS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Faça um join das tabelas criadas anteriormente utilizando o spark.sql no dataframe ‘join_video_comments\n",
        "\n",
        "join_video_comments = spark.sql(\"\"\"\n",
        "    SELECT v.*, c.*\n",
        "    FROM video_table v\n",
        "    JOIN comments_table c\n",
        "    ON v.video_id = c.video_id\n",
        "\"\"\")\n",
        "\n",
        "join_video_comments.show()"
      ],
      "metadata": {
        "id": "MbpexB5QxyTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Faça as mesmas etapas anteriores (1,2,3,4) utilizando repartition e coalesce\n",
        "\n",
        "# Renomeando a coluna 'Video ID' para 'video_id' no DataFrame df_video\n",
        "df_video_cleaned = df_video.withColumnRenamed(\"Video ID\", \"video_id\")\n",
        "# Renomeando a coluna 'Video ID' para 'video_id' no DataFrame df_comments\n",
        "df_comments_cleaned = df_comments.withColumnRenamed(\"Video ID\", \"video_id\")\n"
      ],
      "metadata": {
        "id": "QLzOK_uk1esi"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  Realizar o JOIN com reparticionamento\n",
        "df_video_repartition = df_video_cleaned.repartition(10)\n",
        "df_comments_repartition = df_comments_cleaned.repartition(10)"
      ],
      "metadata": {
        "id": "aAHeTGq4xmkQ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar tabelas temporárias novamente\n",
        "df_video_repartition.createOrReplaceTempView(\"video_table_repartition\")\n",
        "df_comments_repartition.createOrReplaceTempView(\"comments_table_repartition\")"
      ],
      "metadata": {
        "id": "01fEwRO1xqOU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  JOIN com reparticionamento\n",
        "join_video_comments_repartition = spark.sql(\"\"\"\n",
        "    SELECT v.*, c.*\n",
        "    FROM video_table_repartition v\n",
        "    JOIN comments_table_repartition c\n",
        "    ON v.video_id = c.video_id\n",
        "\"\"\")\n",
        "\n",
        "join_video_comments_repartition.show()"
      ],
      "metadata": {
        "id": "OVtXuNz4xroI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Aplicar coalesce\n",
        "df_video_coalesce = df_video_cleaned.coalesce(2)\n",
        "df_comments_coalesce = df_comments_cleaned.coalesce(2)"
      ],
      "metadata": {
        "id": "IjZW5XVSx0Gi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Criar tabelas temporárias para os DataFrames coalesce\n",
        "df_video_coalesce.createOrReplaceTempView(\"video_table_coalesce\")\n",
        "df_comments_coalesce.createOrReplaceTempView(\"comments_table_coalesce\")"
      ],
      "metadata": {
        "id": "1Snuu0bHyKxA"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Realizar o JOIN utilizando as tabelas temporárias coalesce\n",
        "join_video_comments_coalesce = spark.sql(\"\"\"\n",
        "    SELECT v.*, c.*\n",
        "    FROM video_table_coalesce v\n",
        "    JOIN comments_table_coalesce c\n",
        "    ON v.video_id = c.video_id\n",
        "\"\"\")\n",
        "join_video_comments_coalesce.show()"
      ],
      "metadata": {
        "id": "jrR0ID9tyNIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Utilize o explain para entender melhor as duas formas de realizar as etapas e refaça novamente as etapas anteriores (1,2,3,4), utilizando tudo que você já aprendeu para realizar o join e filter apenas com os dados necessários.\n",
        "\n",
        "# Visualizar as formas de realização:\n",
        "\n",
        "#Com repartition\n",
        "join_video_comments_repartition.explain()\n",
        "\n",
        "#Com coalesce\n",
        "join_video_comments_coalesce.explain()\n",
        "\n",
        "#Padronização dos dataframes\n",
        "\n",
        "df_video_cleaned = df_video.select(\n",
        "    *[col(c).alias(c.lower().replace(\" \", \"_\")) for c in df_video.columns]\n",
        ")\n",
        "\n",
        "df_comments_cleaned = df_comments.select(\n",
        "    *[col(c).alias(c.lower().replace(\" \", \"_\")) for c in df_comments.columns]\n",
        ")\n",
        "\n",
        "#  Selecionar apenas as colunas com dados necessários\n",
        "df_video_selected = df_video_cleaned.select(\"video_id\", \"title\", \"keyword\")\n",
        "df_comments_selected = df_comments_cleaned.select(\"video_id\", \"comment\", \"likes\")\n",
        "\n",
        "#  Filtrar apenas os dados não nulos\n",
        "df_video_filtered = df_video_selected.filter(\"video_id IS NOT NULL\")\n",
        "df_comments_filtered = df_comments_selected.filter(\"video_id IS NOT NULL\")\n",
        "\n",
        "#  Criar tabelas temporárias\n",
        "df_video_filtered.createOrReplaceTempView(\"video_table\")\n",
        "df_comments_filtered.createOrReplaceTempView(\"comments_table\")\n",
        "\n",
        "# Realização do JOIN\n",
        "join_video_comments = spark.sql(\"\"\"\n",
        "    SELECT v.video_id, v.title, v.keyword, c.comment, c.likes\n",
        "    FROM video_table v\n",
        "    JOIN comments_table c\n",
        "    ON v.video_id = c.video_id\n",
        "\"\"\")\n",
        "#Mostra o resultado do JOIN\n",
        "join_video_comments.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "QMCAk0vEyY7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Salvando o DataFrame no formato Parquet\n",
        "join_video_comments.write.option('header','true').mode(\"overwrite\").parquet(\"join-videos-comments-otimizado\")\n"
      ],
      "metadata": {
        "id": "6JCAFDQe0sPs"
      },
      "execution_count": 27,
      "outputs": []
    }
  ]
}